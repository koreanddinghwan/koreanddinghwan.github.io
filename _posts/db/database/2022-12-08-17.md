---
title: "[Database] 17 의사결정 지원"
excerpt: "데이터베이스"

categories:
  - database
tags:
 - Decision Support


toc: true
toc_sticky: true

date: 2022-12-11
last_modified_at: 2022-12-12
---

- 운영계 데이터베이스는 트랜젝션에 의해 UPDATE가 주로 일어난다.
- 하지만 분석계 데이터베이스는 `과거 데이터`를 통해 유용한 패턴을 찾아내어 비즈니스 전략에 도움을 주는 것을 목표로한다.
- 기업의 모든 부문의 데이터를 하나로 통합한 매우 큰 데이터를 분석한다.
- UPDATE보다는 INSERT가 주로 일어나는 데이터를 대상으로한다.

<br>

- 분석계 DB의 3가지 분야를 알아보자.

# 1.DW

<img width="587" alt="Screen Shot 2022-12-11 at 8 17 30 PM" src="https://user-images.githubusercontent.com/76278794/206900460-db1cc008-f816-4200-82e1-379b587cdc28.png">

- `Data Warehouse`
	- 과거 데이터의 단순적재
	- 1개 repo에 데이터를 통합한다.
	- 의미론적인 통합이며, 주기적으로 중복된 데이터간 동기화를 수행한다.
	- 운영계 DB에서 ETL로 표준화한 다음, metadata, data Warehouse로 적재한다.

<br>


# 2.OLAP

## 정의

<img width="954" alt="Screen Shot 2022-12-11 at 8 20 29 PM" src="https://user-images.githubusercontent.com/76278794/206900556-d21a4a37-bba9-4844-867e-4223c6ccc59d.png">

- `Online Analytic Processing`
	- `다변량 분석을 위해 생겨났다.`
	- 복잡한 분석 SQL 쿼리와 뷰를 사용한다.
	- 운영계 DB의 OLTP와 대척점에 있다.

<br><br>

## 특징

<img width="576" alt="Screen Shot 2022-12-11 at 8 21 54 PM" src="https://user-images.githubusercontent.com/76278794/206900616-632f933e-88e9-4f49-9d39-a7f30ba057b1.png">

- 분석계 DB는 `Universal schema`로 이루어져있다.
	- 기존 다변량 분석은 X축과 Y축의 데이터로 표현하는데, DB의 속성 수가 많아질수록 다변량 분석은 많아지고, 복잡해지게된다.

<br>

- OLAP은
	- 여러 개의 `수치 속성 데이터들을 분석`할 수 있다.
	- universal schema의 속성들을 `차원속성`과 `측정속성`으로 나눈다.
	- `차원속성(Dimensions)` : 측정 속성이 나타나는 맥락을 의미한다.(지역, 시간, 제품 등)
	- `측정속성(Measures)` : 실제 측정값을 의미한다.(매출액, 판매수익, 예산 등)
	- 측정 속성들을 모두 하나의 점 내부에 표현한다.

<br><br>

## 3D OLAP CUBE

<img width="952" alt="Screen Shot 2022-12-11 at 8 27 15 PM" src="https://user-images.githubusercontent.com/76278794/206900841-3d760418-2d8a-4871-8032-2529a5f0a4ab.png">

- 위와같은 경우에 3차원에 측정치가 2인 그래프를 그릴 수 있는데, 보통 OLAP에선 이를 `3D OLAP CUBE`로 표현한다.

<img width="917" alt="Screen Shot 2022-12-11 at 8 28 51 PM" src="https://user-images.githubusercontent.com/76278794/206900926-4b5c12c9-1b88-46b9-bfa6-be45f2171c34.png">

- 3차원 차원 속성으로 product, region, month가 있고, 측정속성으로는 여러 값이 들어올 수 있다.
	- `Roll up`을 통해 더 집계화된, 합쳐진 데이터를 검색할 수 있으며
		- 상반기, 하반기의 데이터를 합쳐 1년치 데이터를 검색한다  
		<img width="836" alt="Screen Shot 2022-12-11 at 8 39 26 PM" src="https://user-images.githubusercontent.com/76278794/206901392-26ecc85f-b3b9-4d27-b979-3b6a537e7681.png">
	- `Drill down`을 통해 더 상세한 데이터를 검색할 수 있다.
		- 전자제품을 상세화해 캠코더, 모니터, PC등으로 나눈다.  
		<img width="775" alt="Screen Shot 2022-12-11 at 8 39 49 PM" src="https://user-images.githubusercontent.com/76278794/206901424-be476b56-b8d7-425d-a04c-ed171345564d.png">

<br>
<br>

## Star Schema

- 운영계 DB에서 스키마와는 다르게, 분석계 DB는 Universal 스키마에 가깝다.
- 다만, 차원속성과 측정속성의 추가와 삭제를 자유롭게 하기 위해서 table을 분리해뒀다.
	- 차원속성을 담는 table을 `Dimension Table`
	- 측정속성을 담는 table을 `Fact Table`이라고한다.
- Fact Table이 각 Dimension Table의 키를 참조하고 있다.

<img width="631" alt="Screen Shot 2022-12-11 at 8 44 34 PM" src="https://user-images.githubusercontent.com/76278794/206901638-07fba77e-c0c0-4788-bb81-1ae21b8e115e.png">

<br>
<br>

## 분석계 DB 질의의 특징

### Full Scan

- 1개 이상 차원에 대해 집계함수를 자주 사용한다.
	- 집계함수의 특성 상, group by를 자주사용하게되는데 group by자체는 DB내부적으로 `정렬`을 하게된다.
	- 따라서, 필연적으로 `Full Scan`이 발생하게된다.

<br>

### Extensions

- 예전 ROLAP에서는 집계를 위한 질의로 임시테이블을 생성해 해결했지만,
	- extension을 통해 1개 SQL로 해결이 가능해졌다.

<img width="790" alt="Screen Shot 2022-12-11 at 8 52 21 PM" src="https://user-images.githubusercontent.com/76278794/206901997-1a70fe40-9b27-444a-ae60-3d4e158afb5c.png">
- 위의 쿼리는 extension을 통해 아래처럼 질의될 수 있다.

<img width="695" alt="Screen Shot 2022-12-11 at 8 53 05 PM" src="https://user-images.githubusercontent.com/76278794/206902033-f5bfdd9f-e4d5-4261-9cda-92958c689167.png">


<br>

### CUBE질의

- 집계의 편의를 위해 Group By 절에 들어오는 칼럼들의 `모든 가능한 조합`으로 쿼리 결과를 가져온다.

<img width="846" alt="Screen Shot 2022-12-11 at 9 18 08 PM" src="https://user-images.githubusercontent.com/76278794/206903045-a7100bc0-1d45-436d-b7b4-7c5a84381ef2.png">

- `GROUP BY CUBE(A, B);`가 전달된다면,
	- 2 ^ 2의 총 4개의 조합으로 질의 결과가 만들어진다.
	- `단, SELECT절에서 SUM은 CUBE질의에 포함되지 않으므로 항상 포함된다.`


<br>

### RANK()

- OLAP에서 데이터를 정렬하고, rank를 먹히는 특수한 함수이다.

<img width="865" alt="Screen Shot 2022-12-11 at 9 22 18 PM" src="https://user-images.githubusercontent.com/76278794/206903240-bfa881f4-5e9f-4f58-aca7-2885fe26c2ae.png">

- 위 사진에서처럼 제품별 총매출로 정렬해 위에서부터 rank를 생성하고, 이 칼럼으로 WHERE절에서 상위 10개 데이터를 가져온다.


<br>

## 분석계 물리적 DB 디자인

- 분석계 DB의 가장 중요한 특징이 `UPDATE`가 없다는 것임을 명심하자.
- UPDATE가 없다는 것은 INDEX의 약점을 생각할 필요가 없다는 것을 의미하기도한다.
- 그렇게때문에 분석계 DB에서는 bitmap index, bit slice index, project index등의 `여러 인덱스 구조가 생겨났다.`


<br>

- 또한, 스키마가 단순하기에 `운영계 DB보다 많은 쿼리 최적화`를 할 수 있으며,


<br>

- 운영계 DB에서 선택적으로 생성할 수 있었던 `Materialized View`를 기본적으로 선택한다.


<br><br>


# 3.DM

- `Data Mining`
	- DW, OLAP이 정형데이터 분석이라면, DM은 비정형데이터 분석에 맞춰져있다.
	- 데이터베이스에서 흥미로운 트렌드와 지식에 대한 탐색
	- `Non-trivial, implicit, previously unknown, potentially useful`한 정보나, 패턴을 찾아낸다.

<br>
<br>

## DM의 역사

### 1. `Statistics`
	- 1850~1950년대 컴퓨터 나오기 이전시점까지 인간은 통계를 사용했다.
	- 컴퓨터가 없었기에, `손`으로 일일히 데이터를 작성하고, 수집했어야만했기에 시간이 오래걸렸다.
	- `데이터의 양은 물론 작았을 것`이며,
	- `차원도 10개 이하였다.`
	- 수집된 데이터는 사람이 일일히 작성했기에 꺠끗했고,
	- 손쉽게 의사결정이 가능했다.
	- 계산을 쉽게하기위한 단순화된 데이터 모델(가우시안, Poisson)이 생겼다.
		- 추측에 대해 조심히 분석했고,
		- 아웃라이어 데이터는 개별적으로 분석되었다.
	- 우리가 현대에 사용하는 통계학의 이론이 이때 발전했다.
		- 회귀분석
		- 최대 가능도 분석
		- 뉴럴 네트워크 등

<br>

### 2. `Machine Learning`
	- 통계학이 컴퓨터에서 사용되기 시작했다.
		- 100 ~ 100,000 레코드, 5 ~ 250 차원이 사용될 수 있었다.
		- 다만, 초기 컴퓨터는 메모리의 크기가 작아 작은 메모리에 한정되어 사용되었다.
		- 그래서 사람이 읽고, 완벽히 이해하기에는 어려웠다.
	- `데이터 품질이 좋지 않다`.
	- 연산 능력 덕에 `데이터 모델은 더욱 복잡`해졌다.
	- 이론보다는 `emppirical(경험적)으로 테스트`하는 방법론이 우세해졌다.
		- 예상되는 오류를 계산하는 것이 아닌, sample로부터 측정한다.
		- 데이터에 대해 통계학적 추측이 적어짐.
	- 머신러닝을 최대한 자동화한다.
		- 의사결정 트리
		- 클러스터링
		- Genetic
		- K-means 알고리즘 등

<br>

### 3. `Data Mining`
	- 컴퓨터 성능이 이전보다 빨라졌다.(1995 ~ 2006)
		- 최소 45개 속성
		- 100 ~ 1000개의 공통 속성
		- 연결을 통해 1000여개의 속성을 추가할 수 있다.
	- 데이터는 `디스크에만 존재`한다.(메모리에 존재할 수 없을만큼 크기때문)
	- `연산은 완전히 자동화`된다.
		- 좋은 성능의 컴퓨터, 효과적인 알고리즘으로 인간의 개입이 더 어려워짐
	- 더욱 복잡한 데이터 모델이 사용된다.


<br>
<br>

## 데이터마이닝이 생겨난 이유

- 데이터가 너무 많아졌다.
	1. 데이터 수집의 자동화
	2. DB 기술의 발전으로 DW와 다른 저장소에 수많은 데이터가 저장될 수 있다.

- 많은 데이터 속에서 내포된 지식을 찾아내는 것이 중요해졌다.

<br>
<br>

## DM 종류

### Predictive mining

- 지도학습
	- 데이터와 분석을 기반으로 데이터베이스의 모델을 구성하고
	- 알려지지 않은 데이터의 특성과 트렌드를 예측한다.
	- 종류
		- Classification
		- Regression
		- Time Series Analysis
		- Prediction

<br>

- `선형 회귀분석(regreesion)`
	- 알려진 데이터를 기반으로 모델의 계수를 예측한다.
	<img width="988" alt="스크린샷 2022-12-13 18 51 52" src="https://user-images.githubusercontent.com/76278794/207285243-3019cd21-f02f-43d9-87c7-3ed8355c9990.png">
	- 위 데이터를 기반으로 `y = x + 1`이라는 데이터가 만들어진다.


<br>

- `Classification`
	- `decision tree`를 구성한다.
	<img width="1009" alt="스크린샷 2022-12-13 18 54 00" src="https://user-images.githubusercontent.com/76278794/207285784-8db1c184-6f74-4d7d-99ba-2b38d130bbf8.png">

<br>

### Descriptive mining

- 비지도학습
	- `concise(간결), summarative(요약적), informative(유익한), discriminative(구별적인)` 형태로 
	- 업무 관련 데이어 셋이나 개념을 묘사한다.
	- 종류
		- 클러스터링
		- Summarization
		- Association Rules
		- Sequence Discovery
	- 알려진 데이터 내에서 `연관규칙, 패턴규칙, 분류화, 군집과 비군집, 트렌드와 진화분석`을 확인한다.


<br>

- `Association Mining`
	- 트랜젝션 DB, 관계형 DB, 정보 저장소의 데이터들로부터 `빈발하는 패턴, 연관, 상관, 원인 구조를 파악`한다.

- `X(body) -> Y(head)` 의 연관 패턴이 있다고 가정할때, `지지도(suppoert)`와 `신뢰도(confidence)`로 표현한다.
	- `support` : X,Y가 함께 나타나는 트랜젝션 개수(`#{head,body}`) / 전체 트랜젝션 개수(`#t`)
	- `confidence` : X,Y가 함께 나타나는 트랜젝션 개수(`#{head,body}`) / X만 나타나는 트랜젝션 개수(`#head`)


<img width="403" alt="스크린샷 2022-12-13 19 31 48" src="https://user-images.githubusercontent.com/76278794/207294249-734d4e96-9290-4736-a335-54fca3c0d39b.png">
- 위와같은 트래젝션이 있을때 `{Milk, Diaper} -> { Beer }`의 연관규칙을 찾는다고 생각해보자.
	- #body : 3
	- #{head, body} : : 2
	- #T : 5

- 지지도(support) = `#{head, body} / #T` = 2 / 5 = 0.4
- 신뢰도(confidence) = `#{head, body} / #body` = 2 / 3 = 0.67


<br>


- `Apriori Algorithm`
	- 단계별로 후보군을 생성하고 테스트하는 것을 반복한다.
	- 최소 지지도를 지정하고, 그 아래 숫자의 후보군은 없애고 다음 단계로 넘어간다.
	- 1단계  
	<img width="716" alt="스크린샷 2022-12-13 19 38 15" src="https://user-images.githubusercontent.com/76278794/207295594-7b90d77e-5c09-455d-82af-9693c2f104aa.png">
	- 2단계 : 1단계에서 min_sup 미만인 후보군 삭제한 후보군의 2레벨 후보군  
	<img src="https://user-images.githubusercontent.com/76278794/207296594-1e5fa1f6-d9b1-4952-a695-1e3c1236823d.jpeg">
	- 3단계  
	<img width="315" alt="스크린샷 2022-12-13 19 45 47" src="https://user-images.githubusercontent.com/76278794/207297218-63e3f871-8dad-4599-8560-20879bc45055.png">

<br>
<br>

- `Cluster 분석`
	- 데이터 집합을 군집으로 나눈다.
	- cluster : 데이터의 집합.
	- 군집 내부 유사도는 높지만
	- 군집간 유사도는 낮춘다.

- 용어
	<img width="590" alt="스크린샷 2022-12-13 19 50 29" src="https://user-images.githubusercontent.com/76278794/207298209-ee880fab-ac21-4fab-aee2-423dc46a8613.png">
	- cluster : 데이터의 집합.
	- Outliers : 어느 군집에도 속하지 않는다.

- 유사도 측정
	- 두 데이터가 얼마나 유사한지 나타내는 수치 측정
	- 데이터끼리 비슷할수록 높다.
	- 종종 [0, 1]까지 떨어진다.

<br>

- 점들 간, 거리계산을 위해서는 `Euclidean Distance(유클리드 거리)`를 사용한다.

<br>

- `K-Means Clustering Method`
	- 처음에 모든 데이터는 하나의 클러스터에 속한다.
	- 클러스터링할때 클러스터링의 기준
	- `K는 클러스터의 개수를 의미한다.`
		- 일반적으로 N개의 군집을 찾는다고하면, K는 3배정도 잡는다.
		- 그 이유는 군집을 세세하게 나눈 후, 그루핑하는 방법이 더 편하기때문이다.
	- 프로세스
		1. K를 정한다.(N개 군집 찾을때 N * 3정도)
		2. 맨 처음에는 랜덤하게, 혹은 수동으로 K개의 mean값을 하나 정한다.
		3. 각 값별로 가장 거리가 가까운 mean값의 군집으로 넣는다.
		4. 모든 값이 군집에 속하게되면 군집마다 중앙값을 다시 계산하고, 3을 반복한다.
		<img width="1680" alt="스크린샷 2022-12-08 17 11 00" src="https://user-images.githubusercontent.com/76278794/207322234-d036080c-acd9-458e-996b-dcb14c8211dd.png">

