---
title: "[Database] 18 빅데이터와 Hadoop"
excerpt: "데이터베이스"

categories:
  - database
tags:
 - Hadoop


toc: true
toc_sticky: true

date: 2022-12-13
last_modified_at: 2022-12-14
---

# 빅데이터란

- 휴대폰이 발전하며 개인화가 폭발적으로 증가했다.
- 실시간으로 데이터를 수집하며 이전과는 비교도 안되는 양의 데이터가 생겨났다.
- 일반적으로 `빅데이터`는  `Hadoop`을 사용함으로써 이런 대용량 데이터들을 처리할 수 있게되었음을 의미한다.

<br>

## 정의

- 이전의 기술로는 저장/관리/분석하기 힘들 정도로 큰 데이터를 의미.
- 하지만 단순히 큰 데이터를 의미하는건 아니다.
- `3V`로 설명된다.

<br>

### 3V

1. `VOLUME`
	- 테라바이트급의 레코드, 트랜젝션, 테이블과 파일 처리
2. `VELOCITY`
	- Batch단위로 거의 실시간에 가깝게, 스트림처리
3. `VARIETY`
	- 정형,비정형,반정형을 모두 처리

- 위와같은 성격을 지닌 데이터를 처리하는 기술을 `빅데이터 기술`이라부르고,
	- 분산병렬처리 기술인 하둡과 함께 시작되었다.

<br>

# Hadoop

- 2007년도에 발표된 하둡은 2011년부터 본격적으로 사용된다.

## 정의

1. 큰 크기의 데이터를 저장하고, 분석할 수 있는 플랫폼
2. batch-oriented
3. strong-consistent  
의 주요 특징을 가지고 있기 때문에 아래의 상황에서 최대 효율을 가진다.
	- `큰 규모의 배치` 분석
	- `비정형/반정형` 데이터
	- `계층이 없는(flat)` 파일

<br>

## 특징

1. Fault-tolerant : 1.5개정도의 `중복`도로 노드 한개가 죽더라도 다른 노드에서 데이터를 처리한다.이는 HDFS에서 heartbeat와 연관있다.
2. High-throughput : `병렬`로 처리하기때문에 많은 처리량
3. Large-scale data : 큰 규모 데이터에 알맞다.
4. Streaming Access : 파일 시스템 데이터를 잘게쪼개 접근한다.
5. commodity hardware : 값싼 여러 하드웨어로 만들 수 있다.
6. JAVA API : 이식성을 위함
7. 브라우저로 HDFS 인스턴스의 파일을 확인하는데에 사용될 수 있다.

<br>

## 주요 시스템

### HDFS

<img width="1013" alt="스크린샷 2022-12-13 23 43 38" src="https://user-images.githubusercontent.com/76278794/207363983-9b642ef8-dac5-4753-a17b-8de265971b35.png">

- HDFS는 Master-Slave 아키텍쳐이다.
- 1개의 HDFS클러스터는 1개의 name node와 여러개의 data node로 이루어져 있다.
- Hadoop의 master node는 각 datanode들이 보내는 heartbeat를 확인해 datanode들에 할당한 작업이 처리되고있는지 확인한다.
- 만약 heartbeat interval 내에 수신되지 않으면 다른 datanode에 작업을 부여한다.

<br>

### Map Reduce방식

<img width="845" alt="스크린샷 2022-12-14 00 01 47" src="https://user-images.githubusercontent.com/76278794/207368463-e2e4fa68-f8ae-461f-addd-b3bc0a161784.png">

- 처리 시, 로컬에서 카운트하고, reduce에서 데이터들을 병합해 결과를 만들어낸다.
1. 각 로컬 input hdfs에 나눠진 데이터들에 대해 map함수를 적용해 정렬한 후,
2. 정렬된 결과를 output hdfs에서 병합한 후, reduce함수를 적용한다.
3. 이때 각각 병합된 결과는 replicated된다.


<br>
<br>


# Spark

## 특징

1. `batch, streaming, interactive` 연산을 함께할 수 있다.
2. 정교한 알고리즘을 개발할 수 있다.
3. Hadoop과 함꼐 사용할 수 있다. 
4. hadoop의 mapreduce가 Hive기반이라면, Spark는 Spark SQL기반이다.
	- 정형데이터를 처리할 수 있다.
5. SQL을 사용해 RDD(Resilient Distributed Dataset)를 벙렬처리할 수 있다.

<br>

### in-memory processing

<img width="1271" alt="스크린샷 2022-12-14 00 31 17" src="https://user-images.githubusercontent.com/76278794/207375448-6ac5a906-ef29-4505-9cbc-ed85f70f4358.png">

- 하둡은 dist read/write 연산이 자주 일어나지만, Spark는 `in-memory`연산을 지원한다.
- 메모리 내에서 일어나기때문에
	- `빠른 연산`
	- `휘발성`의 특징을 가진다.
- 따라서 큰 시스템에서는 사용되지 않는다.

<br>

### Dataset

- 스파크는 RDD와 Dataframe 모두를 처리할 수 있다.
<img width="778" alt="스크린샷 2022-12-14 00 42 53" src="https://user-images.githubusercontent.com/76278794/207378320-c37cc38e-85f3-417d-b46b-36a8feef2aa6.png">

<br>

### Stream Processing

<img width="603" alt="스크린샷 2022-12-14 00 47 39" src="https://user-images.githubusercontent.com/76278794/207379441-360095e2-0521-4381-85bb-f7ce97cf4059.png">
- in-memory에서 micro batch로 잘라서 매우 작은 작업으로 나눠서 처리해 실시간으로 결과를 보내준다.
- 이에따라 사용자는 실시간처럼 느끼게된다.


<br><br>


# Cloud Databases

- 값싼 여러대의 하드웨어, 서버를 데이터 집약적 어플리케이션을 올릴 수 있다.
- 기본적으로,
	- 탄력적이며
	- fault-tolerance하고
	- 자동으로 공급된다.

<br>

## 특징

1. scale-up 은 불가능하다.(비싼 기기로 성능 향상은 하지 못함)
2. scale-out은 가능(여러대의 값싼 기기로 데이터를 분산한다.)
3. sharding(수직, vertical split), Horizontal(수평)적 데이터 분산이 가능.
4. 어플리케이션의 벙렬접근관리
5. read,write에 대한 척도
6. 투명하지 않으므로 분산되어있다는 것을 항상 명심해야한다.

<br><br>

## not consistent

- 클라우드 컴퓨팅에서 ACID는 지켜지기 어렵다.
- NOSQL에서는 CAP이론에서 consistency, availability, partition tolerance 모두는 지켜지기 어렵다고한다.
- CLOUD DB는 업데이트가 주요 목적이 아니므로, consistency는 버려진다.
- 대신, avaliability, partition tolerance를 확보한다.
	- Availability : replication으로 검색,분석 시 항상 존재
	- Partition tolerance : network일부분이 꺼져도 데이터를 가져올 수 있어야한다.


<br>

## Consistency Model

- NOSQL에서는 consistency model에 따라 visibility rule과 update order을 결정한다.
- 특정 시점에서 A에 업데이트 된 데이터가 B에선 업데이트 안되어있을수도 있다는 의미이다.
- 그래서 `Eventually Consistency`라고한다.(`충분한 시간이 지난뒤에야 consistency가 보장`)


<br><br>

## BASE-ACID와 정반대

1. `Basically Available` : 전체 시스템의 fault되지 않는다.
2. `Soft state` : data의 복사본들이 특정 시점에서 consistency를 보장하지 않는다.
3. `Eventually Consistent` : 특정 시간 뒤에야 consistent해진다.


<br><br>

# CAP theorem

<img width="1465" alt="스크린샷 2022-12-14 01 36 25" src="https://user-images.githubusercontent.com/76278794/207391060-47e1f772-85f9-4b8f-843d-c5a98ffaa90b.png">
1. Consistency : 데이터의 일관성
2. Availability : 시스템 한 부분의 fail이 전체의 fail로 이어지나?
3. Partition : network가 다운돼도 다른 segment에서 가져올 수 있는가?

- NOSQL은 이 3가지 모두를 달성할 수 없다고 말하는 이론.
- `C,A`모두를 달성할수는 없다고 말한다. 분산은 곧 일관성의 저하로 이어지기때문.
- 전통적인 DB는 C를 중요시 여기나, 일관성이 중요하지 않은 웹 어플리케이션 중에서는 A를 우선시하기도한다.
- `C(일관성)을 줄이면, replication을 쉽게할 수 있고,`
- `A(가용성)을 줄이면, concurrency control이 쉬워진다.`

<br><br>

# NOSQL

## 특징

- NOT-ONLY SQL
- 일반적으로 관계연산을 지원하지 않으며
- 고정된 테이블 스키마가 필요하지 않아 수평적 확장이 용이하며
- 대부분 오픈소스이다.

- ACID중 1개를 포기(CAP theorem)
- replication을 지원한다.

- join 연산과 참조무결성제약을 지원하지 않을 수 있다.


## 종류

<img width="710" alt="스크린샷 2022-12-14 07 44 19" src="https://user-images.githubusercontent.com/76278794/207460809-e86499b5-092c-4262-9918-df8a634d00da.png">

<br><br>

# 빅데이터 분석

- 정형데이터분석 : `상태관리`가 주 목적
- 빅데이터 분석 : `변화관리`가 주 목적
- 지속적으로, 빠르게 발생하는 시계열적 특성을 가지는 무한한 데이터를 의미.
- 실시간에 패턴을 분석하고, 질의를 처리하고 계산해야한다.
- 데이터 스트림의 `특정순간`에 질의를 하기 때문에
	- 최대 1번만 분석이 가능하며
	- 메모리 바인딩을 통해 분석 속도를 높인다.



































